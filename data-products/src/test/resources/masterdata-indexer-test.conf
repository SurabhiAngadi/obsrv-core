# do not delete this file
env=local

redis.host="localhost"
redis.port="6379"
redis_scan_count=1000
redis_maxPipelineSize=1000
cloudStorage.container="obsrv-data"
cloudStorage.provider="local"
cloudStorage.accountName="obsrv" # Is required when azure is provider. Will only be used when azure is the provider
druid.indexer.url="http://localhost:8888/druid/indexer/v1/task"
druid.datasource.delete.url="http://localhost:8888/druid/coordinator/v1/datasources/"

metrics {
 topicName = "spark.stats"
}

kafka {
    bootstrap.servers = "localhost:9092"
}

postgres {
    host = localhost
    port = 5432
    maxConnections = 2
    user = "postgres"
    password = "postgres"
    database="postgres"
}
local_inputSource_spec="{spec:{ioConfig:{type:index_parallel,inputSource:{type:local,baseDir:filepath,filter:**json.gz}}}}"
cloud_inputSource_spec="{spec:{ioConfig:{type:index_parallel,inputSource:{type:"cloudStorage.provider",objectGlob:**.json.gz,prefixes:[filePath]}}}"

